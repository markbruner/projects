{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94979707-7efd-4dbe-b26a-a52f314cd0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.firefox_profile import FirefoxProfile\n",
    "\n",
    "# Import the exception class\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementNotInteractableException  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b141fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r'C:\\Users\\markd\\projects\\Hamilton County Homes'\n",
    "os.chdir(path)\n",
    "\n",
    "# homes1 = pd.read_csv('2009 to 2010 House Sales.csv')\n",
    "# homes2 = pd.read_csv('2011 to 2012 House Sales.csv')\n",
    "# homes3 = pd.read_csv('2013 to 2014 House Sales.csv')\n",
    "# homes4 = pd.read_csv('2015 to 2015 House Sales.csv')\n",
    "# homes5 = pd.read_csv('2016 House Sales.csv')\n",
    "# homes6 = pd.read_csv('2017 House Sales.csv')\n",
    "# homes = pd.concat([homes1,homes2,homes3,homes4,homes5, homes6],axis=0)\n",
    "# homes.to_csv('2009 to 2017 House Sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06a283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parcel_num = list(homes.parcel_number.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf486e5-9dc8-49da-bb2b-e0fe70e8c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "firefox_profile = FirefoxProfile()\n",
    "firefox_profile.set_preference(\"javascript.enabled\", True)\n",
    "options.profile = firefox_profile\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "def get_free_proxies(driver):\n",
    "    driver.get('https://sslproxies.org')\n",
    "\n",
    "    table = driver.find_element(By.TAG_NAME, 'table')\n",
    "    thead = table.find_element(By.TAG_NAME, 'thead').find_elements(By.TAG_NAME, 'th')\n",
    "    tbody = table.find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "    headers = []\n",
    "    for th in thead:\n",
    "        headers.append(th.text.strip())\n",
    "\n",
    "    proxies = []\n",
    "    for tr in tbody:\n",
    "        proxy_data = {}\n",
    "        tds = tr.find_elements(By.TAG_NAME, 'td')\n",
    "        for i in range(len(headers)):\n",
    "            proxy_data[headers[i]] = tds[i].text.strip()\n",
    "        proxies.append(proxy_data)\n",
    "    driver.quit()\n",
    "    return proxies\n",
    "\n",
    "\n",
    "free_proxies = get_free_proxies(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181aea6c-485c-48ca-82d3-2ea1df3773f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL of webscraping\n",
    "BASE_URL = 'https://wedge.hcauditor.org/'\n",
    "\n",
    "my_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:53.0) Gecko/20100101 Firefox/53.0'\n",
    "\n",
    "# The radio button to select to search by sales. \n",
    "SALES_XPATH = '//*[@id=\"search_radio_sales\"]'\n",
    "\n",
    "# Form values to filter search.\n",
    "query_values = ['350000', '100000', '1200', '500', '2']\n",
    "query_ids = ['sale_date_high', 'sale_date_low', 'sale_price_high', 'sale_price_low', 'finished_sq_ft_high', 'finished_sq_ft_low', 'bedrooms_low']\n",
    "CONVENTIONAL_XPATH = '//*[@id=\"ms-cama_style\"]/div[1]/ul/li[1]'\n",
    "AC_XPATH = '//*[@id=\"ac_yes\"]'\n",
    "SCHOOL_DISTRICT_XPATHS = [\n",
    "    # '//*[@id=\"ms-adv-school-dist\"]/div[1]/ul/li[7]',\n",
    "    # # '//*[@id=\"ms-adv-school-dist\"]/div[1]/ul/li[8]',\n",
    "    # # '//*[@id=\"ms-adv-school-dist\"]/div[1]/ul/li[9]',\n",
    "    # # '//*[@id=\"ms-adv-school-dist\"]/div[1]/ul/li[10]',\n",
    "    # # '//*[@id=\"ms-adv-school-dist\"]/div[1]/ul/li[20]',\n",
    "    # # '//*[@id=\"ms-adv-school-dist\"]/div[1]/ul/li[23]',\n",
    "]\n",
    "# Form search button\n",
    "SEARCH_BUTTON_XPATH = '//*[@id=\"sales-criteria\"]/div[3]/button[1]'\n",
    "\n",
    "# Search result tables XPATHs\n",
    "RESULTS_TABLE_XPATH = '//*[@id=\"search-results\"]'\n",
    "NEXT_PAGE_XPATH = '//*[@id=\"search-results_next\"]'\n",
    "SEARCH_RESULTS_XPATH = '//*[@id=\"search-results_info\"]'\n",
    "\n",
    "# Search result tables \"first page\" XPATH button\n",
    "FIRST_PAGE_XPATH = '//*[@id=\"search-results_paginate\"]/span/a[1]'\n",
    "\n",
    "# First row of table XPATH\n",
    "HOUSE_TABLE_ROW1_XPATH = '//*[@id=\"search-results\"]/tbody/tr[1]'\n",
    "\n",
    "# Property summary individual cells XPATH\n",
    "PARCEL_ID_XPATH = '//*[@id=\"parcel-header-info\"]/div[1]'\n",
    "APPRAISAL_AREA_XPATH = '//*[@id=\"property_information\"]/tbody/tr[2]/td[1]/div[2]'\n",
    "SCHOOL_DISTRICT_XPATH = '//*[@id=\"property_information\"]/tbody/tr[1]/td[1]/div[4]'\n",
    "TAX_RATE_XPATH = '//*[@id=\"property_information\"]/tbody/tr[4]/td[2]/div[2]'\n",
    "ANNUAL_TAX_XPATH = '//*[@id=\"property_information\"]/tbody/tr[4]/td[3]/div[2]'\n",
    "OWNER_XPATH = '//*[@id=\"property_information\"]/tbody/tr[3]/td[1]/div[2]'\n",
    "\n",
    "PROPERTY_SUMMARY_XPATH = '//*[@id=\"parcel-tabs\"]/a[1]'\n",
    "# Property summary tables XPATH\n",
    "APPRAISAL_TABLE_XPATH = '//*[@id=\"property_overview_wrapper\"]/table[1]'\n",
    "TAX_TABLE_XPATH = '//*[@id=\"tax-credit-value-summary\"]'\n",
    "\n",
    "#Transfer table of home sales\n",
    "TRANSFER_TAB_XPATH = '//*[@id=\"parcel-tabs\"]/a[4]'\n",
    "TRANSFER_TABLE_XPATH = '/html/body/div/div[3]/div[2]/table'\n",
    "\n",
    "# On the property summary page, this is the Next button XPATH\n",
    "NEXT_PROPERTY_XPATH = '/html/body/div/div[2]/div/div[2]/a[3]'\n",
    "\n",
    "# This is the new search XPATH\n",
    "NEW_SEARCH_XPATH = '//*[@id=\"sidebar\"]/div[2]/a[1]'\n",
    "    \n",
    "# Initialize web driver\n",
    "def init_driver():\n",
    "    options = Options()\n",
    "    firefox_profile = FirefoxProfile()\n",
    "    firefox_profile.set_preference(\"javascript.enabled\", True)\n",
    "    options.profile = firefox_profile\n",
    "    RAND_INT = random.randint(0,len(free_proxies))\n",
    "    proxy_server_url = free_proxies[RAND_INT]['IP Address']\n",
    "    options.add_argument(f'--proxy-server={proxy_server_url}')\n",
    "    options.add_argument(f\"--user-agent={my_user_agent}\")\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    driver.get(BASE_URL)\n",
    "    return driver, wait\n",
    "\n",
    "# Helper functions\n",
    "def click_element(wait,xpath):\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, xpath))).click()\n",
    "\n",
    "def fill_form(driver,wait,ids, values):\n",
    "    for id, value in zip(ids, values):\n",
    "        wait.until(EC.presence_of_element_located((By.ID, id)))\n",
    "        driver.find_element(By.ID, id).send_keys(value)\n",
    "\n",
    "def get_text(wait,xpath):\n",
    "    text = wait.until(EC.presence_of_element_located((By.XPATH, xpath))).text\n",
    "    return text\n",
    "    \n",
    "def scrape_table(wait,xpath):\n",
    "    html = wait.until(EC.visibility_of_element_located((By.XPATH, xpath))).get_attribute(\"outerHTML\")\n",
    "    html_io = StringIO(html)\n",
    "    return pd.read_html(html_io)[0]\n",
    "\n",
    "def find_click_row(driver,wait,xpath):\n",
    "    row = driver.find_element(By.XPATH,xpath)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", row)\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "    try:\n",
    "        row.click()\n",
    "    except ElementNotInteractableException:\n",
    "        driver.execute_script(\"arguments[0].click();\", row)\n",
    "\n",
    "def transform_appraisal_table(table):\n",
    "    table = table.transpose().reset_index(drop=True)\n",
    "    table.columns = table.iloc[0]\n",
    "    return (table.drop(0)\n",
    "                .drop(['Year Built', 'Deed Number'], axis=1)\n",
    "                .rename(columns={'# Bedrooms': 'Bedrooms',\n",
    "                                 '# Full Bathrooms': 'Full Baths',\n",
    "                                 '# Half Bathrooms': 'Half Baths'}))\n",
    "    \n",
    "def transform_tax_table(table):\n",
    "    table = table.transpose().reset_index(drop=True)\n",
    "    table.columns = table.iloc[0]\n",
    "    return table.drop(0)\n",
    "\n",
    "# Function to format column names\n",
    "def format_column_name(name):\n",
    "    # Replace spaces with underscores\n",
    "    name = name.replace(' ', '_')\n",
    "    # Remove special characters\n",
    "    name = re.sub(r'[^A-Za-z0-9_]+', '', name)\n",
    "    # Convert to lowercase (optional)\n",
    "    name = name.lower()\n",
    "    return name\n",
    "\n",
    "#Main scraping logic\n",
    "def main(END_DATE_STR,START_DATE_STR):\n",
    "\n",
    "    \n",
    "    driver, wait = init_driver()\n",
    "    all_data = []\n",
    "    appraisal_data = []\n",
    "    tax_data = []\n",
    "    transfer_data = []\n",
    "\n",
    "    click_element(wait,SALES_XPATH)  # Example XPath, replace with actual\n",
    "    # Fill out the form\n",
    "    fill_form(driver,wait,query_ids, [END_DATE_STR,START_DATE_STR] + query_values)\n",
    "\n",
    "    # Click conventional style\n",
    "    click_element(wait,CONVENTIONAL_XPATH)\n",
    "\n",
    "    # Click ac checklist\n",
    "    click_element(wait,AC_XPATH)\n",
    "\n",
    "    # Click on specific school districts\n",
    "    # for xpath in SCHOOL_DISTRICT_XPATHS:\n",
    "    #     click_element(wait,xpath)\n",
    "\n",
    "    # Click on the search button\n",
    "    click_element(wait,SEARCH_BUTTON_XPATH)\n",
    "    time.sleep(1)\n",
    "    NUM_ENTRIES = pd.to_numeric(get_text(wait,SEARCH_RESULTS_XPATH).split(' ')[5])\n",
    "        \n",
    "    while True:\n",
    "        # Scrape data from the current page\n",
    "        table = scrape_table(wait,RESULTS_TABLE_XPATH)\n",
    "        all_data.append(table)\n",
    "    \n",
    "        # Check if the 'Next' button exists and is clickable\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, NEXT_PAGE_XPATH)\n",
    "            if \"disabled\" in next_button.get_attribute('class'):\n",
    "                break  # 'Next' button is disabled, so break the loop\n",
    "            else:\n",
    "                next_button.click()  # Click the 'Next' button\n",
    "                # Wait for the next page to load and then scrape the table\n",
    "                # (Assuming some wait condition is needed here)\n",
    "                table = scrape_table(wait,RESULTS_TABLE_XPATH)\n",
    "                all_data.append(table)\n",
    "                # WAIT_TIME = random.uniform(30,60)\n",
    "                # time.sleep(WAIT_TIME)\n",
    "    \n",
    "        except NoSuchElementException:\n",
    "            # 'Next' button doesn't exist, so break the loop\n",
    "            break\n",
    "    CURRENT_PAGE = 0\n",
    "    #Goes to the first search page        \n",
    "    click_element(wait,FIRST_PAGE_XPATH)\n",
    "\n",
    "    #Grabs info from the first row in the table and \n",
    "    #then scrolls through all properties grabbing the same info.\n",
    "    find_click_row(driver,wait,HOUSE_TABLE_ROW1_XPATH)\n",
    "\n",
    "    while CURRENT_PAGE < NUM_ENTRIES:\n",
    "        PARCEL_ID = get_text(wait,PARCEL_ID_XPATH).split('\\n')[1]\n",
    "        if PARCEL_ID in parcel_num:\n",
    "            driver.find_element(By.XPATH, NEXT_PROPERTY_XPATH).click()\n",
    "            WAIT_TIME = random.uniform(5,10)\n",
    "            time.sleep(WAIT_TIME)\n",
    "            CURRENT_PAGE += 1   \n",
    "        else:\n",
    "            appraisal_table = scrape_table(wait,APPRAISAL_TABLE_XPATH)\n",
    "            # Scrape data from the current page\n",
    "            appraisal_table = transform_appraisal_table(appraisal_table)\n",
    "            appraisal_table['annual_tax'] = get_text(wait,ANNUAL_TAX_XPATH)\n",
    "            appraisal_table['effective_tax_rate'] = get_text(wait,TAX_RATE_XPATH)\n",
    "            appraisal_table['parcel_id'] = PARCEL_ID\n",
    "            parcel_num.append(PARCEL_ID)\n",
    "            appraisal_table['school_district'] = get_text(wait,SCHOOL_DISTRICT_XPATH)\n",
    "            appraisal_table['appraisal_area'] = get_text(wait,APPRAISAL_AREA_XPATH)\n",
    "            appraisal_table['owner_address'] = get_text(wait,OWNER_XPATH)\n",
    "            appraisal_data.append(appraisal_table)\n",
    "\n",
    "            tax_table = transform_tax_table(scrape_table(wait,TAX_TABLE_XPATH))\n",
    "            tax_table['parcel_id'] = get_text(wait,PARCEL_ID_XPATH).split('\\n')[1]\n",
    "            tax_data.append(tax_table)\n",
    "\n",
    "            click_element(wait,TRANSFER_TAB_XPATH)\n",
    "            transfer_table = scrape_table(wait,TRANSFER_TABLE_XPATH)\n",
    "            transfer_table.columns =transfer_table.iloc[0,:]\n",
    "            transfer_table = transfer_table.drop(0,axis=0)\n",
    "            transfer_table['parcel_id'] = get_text(wait,PARCEL_ID_XPATH).split('\\n')[1]\n",
    "            transfer_data.append(transfer_table)\n",
    "            \n",
    "            click_element(wait,PROPERTY_SUMMARY_XPATH)\n",
    "                        \n",
    "            driver.find_element(By.XPATH, NEXT_PROPERTY_XPATH).click()\n",
    "            WAIT_TIME = random.uniform(5,10)\n",
    "            time.sleep(WAIT_TIME)\n",
    "            CURRENT_PAGE += 1       \n",
    "                    \n",
    "    driver.find_element(By.XPATH, NEW_SEARCH_XPATH).click()\n",
    "\n",
    "    all_data_df = (pd.concat(all_data,axis=0)\n",
    "                        .reset_index()\n",
    "                        .drop('index',axis=1))\n",
    "    appraisal_data_df = (pd.concat(appraisal_data,axis=0)\n",
    "                        .reset_index()\n",
    "                        .drop('index',axis=1))\n",
    "    tax_data_df = (pd.concat(tax_data,axis=0)\n",
    "                        .reset_index()\n",
    "                        .drop('index',axis=1))\n",
    "    transfer_history_df = (pd.concat(transfer_data,axis=0)\n",
    "                        .reset_index()\n",
    "                        .drop('index',axis=1))\n",
    "    all_data_df = (all_data_df.merge(appraisal_data_df, left_on = 'Parcel Number', right_on = 'parcel_id', how = 'left')\n",
    "                   .merge(tax_data_df, left_on = 'Parcel Number', right_on='parcel_id', how = 'left')).merge(transfer_history_df, left_on = 'Parcel Number', right_on='parcel_id', how = 'left')\n",
    "    \n",
    "    \n",
    "    driver.quit()\n",
    "    return all_data_df, all_data, appraisal_data, tax_data,transfer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14dbbc8-2cd0-4715-97bd-575cd908200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Unable to parse string \"1,000\" at position 0\n",
      "An error occurred: Reindexing only valid with uniquely valued Index objects\n"
     ]
    }
   ],
   "source": [
    "# Year constraints\n",
    "YEAR_START = 2019\n",
    "time_slices = []\n",
    "if __name__ == \"__main__\":\n",
    "    homes_new = pd.read_csv(f'{YEAR_START-1} House Sales.csv')\n",
    "    homes = pd.read_csv(f'2009 to {YEAR_START-2} House Sales.csv')\n",
    "    homes = pd.concat([homes,homes_new],axis=0)\n",
    "    homes.to_csv(f'2009 to {YEAR_START-1} House Sales.csv')\n",
    "    parcel_num = list(homes.parcel_number.unique())\n",
    "    completed = False\n",
    "    START_DATE = datetime.strptime(f'01/01/{YEAR_START}','%m/%d/%Y')\n",
    "    END_DATE = datetime.strptime(f'12/31/{YEAR_START}','%m/%d/%Y')\n",
    "    time_slices = []\n",
    "    time_slices.append(pd.date_range(start=START_DATE,end=END_DATE,periods=2))\n",
    "    time_slices.append(pd.date_range(start=START_DATE,end=END_DATE,periods=3))\n",
    "    time_slices.append(pd.date_range(start=START_DATE,end=END_DATE,periods=4))\n",
    "    for time_slice in time_slices:\n",
    "        for i in range(len(time_slice) - 1):\n",
    "            START_DATE_STR = datetime.strftime(time_slice[i],'%m/%d/%Y')\n",
    "            END_DATE_STR = datetime.strftime(time_slice[i+1],'%m/%d/%Y')\n",
    "            try:\n",
    "                final_df, final_data, apprasial_data, tax_data, transfer_data = main(END_DATE_STR,START_DATE_STR)\n",
    "                final_df = final_df.drop(final_df.columns[45], axis=1)\n",
    "\n",
    "                # Format each column name\n",
    "                formatted_column_names = [format_column_name(col) for col in final_df.columns]\n",
    "\n",
    "                # Assign the formatted names back to the DataFrame\n",
    "                final_df.columns = formatted_column_names\n",
    "                final_df = final_df.drop([\n",
    "                    'last_transfer_date',\n",
    "                    'last_sale_amount',\n",
    "                    'parcel_id_x',\n",
    "                    'parcel_id_y',\n",
    "                    'transfer_date_x',\n",
    "                    'bbb'], axis = 1)\n",
    "                final_df = final_df.drop_duplicates()\n",
    "                final_df = final_df.rename(columns={\n",
    "                                                '_of_parcels_sold': 'num_parcels_sold',\n",
    "                                                'transfer_date_y':'transfer_date'\n",
    "                                            })\n",
    "                # Save or process final_data as needed\n",
    "                final_df.to_csv(f'{YEAR_START} House Sales.csv')\n",
    "                completed = True\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "        if completed:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
